
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="StyleSheet" href="./files/style.css" type="text/css" media="all"> 

<title>Track and Segment: An Iterative Unsupervised Approach for Video Object Proposals</title> 
<style type="text/css">
#primarycontent h1 {
	font-variant: small-caps;
}
#primarycontent h3 {
}
#primarycontent teasertext {
	text-align: center;
}
#primarycontent p {
	text-align: center;
}
#primarycontent {
	text-align: justify;
}
#primarycontent p {
	text-align: justify;
}
#primarycontent p iframe {
	text-align: center;
}
.featart {
  margin:4px;
}
</style>
<script async="" src="./files/analytics.js"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-32372780-2', 'auto');
  ga('send', 'pageview');

</script>
<script type="text/javascript">
  function togglevis(elid){
    el=document.getElementById(elid);
    aelid=elid+"a";
    ael=document.getElementById(aelid);
    if(el.style.display=='none'){
      el.style.display='inline-table';
      ael.innerHTML="[Hide BibTex]";
    }else{
      el.style.display='none';
      ael.innerHTML="[Show BibTex]";
    }
  }
</script>
</head> 
<body itemscope="" itemtype="http://schema.org/ScholarlyArticle"> 
<div id="primarycontent"> 
<p class="hiddenDiv" itemprop="url"></p>
<h1 align="center" itemprop="name"><strong>Track and Segment: An Iterative Unsupervised Approach for Video Object Proposals</strong></h1>
<h1 align="center"><img src="./files/teaser.png" itemprop="image" width="800" alt="teaserImage"></h1>
<p style="text-align:center;margin-bottom:-15px;font-size:1em;font-weight:bold;">Presented at <a href="http://cvpr2016.thecvf.com/" target="_blank">CVPR 2016</a></p>
<h3>People</h3>

<ul id="people" itemprop="accountablePerson">
<li><a href="http://fanyix.cs.ucdavis.edu/">Fanyi Xiao</a></li>
<li><a href="http://web.cs.ucdavis.edu/~yjlee/">Yong Jae Lee</a></li>
</ul>
<h3>Abstract</h3>


<p style="padding-left: 10px;	padding-right: 10px;">
We present an unsupervised approach that generates a diverse, ranked set of bounding box and segmentation video object proposals---spatio-temporal tubes that localize the foreground objects---in an unannotated video.  In contrast to previous unsupervised methods that either track regions initialized in an arbitrary frame or train a fixed model over a cluster of regions, we instead discover a set of easy-to-group instances of an object and then iteratively update its appearance model to gradually detect harder instances in temporally-adjacent frames.  Our method first generates a set of spatio-temporal bounding box proposals, and then refines them to obtain pixel-wise segmentation proposals.  We demonstrate state-of-the-art segmentation results on the SegTrack v2 dataset, and bounding box tracking results that perform competitively to state-of-the-art supervised tracking methods.
</p>


<h3>Paper</h3>
<table><tbody><tr>
  <td>
  </td>
  <td valign="middle">
    <p style="text-align:left;margin-top:5px;">
    <span style="font-size:12px">
    </span></p>
    <p>
    </p>

<p style="margin-top:10px;">

</p><p style="text-align:left;"><span style="font-size:4px;">&nbsp;<br></span> Fanyi Xiao and Yong Jae Lee </br><a href="./files/cvpr2016.pdf"><b>Track and Segment: An Iterative Unsupervised Approach for Video Object Proposals</b></a> <br>In <i>CVPR 2016</i>
   <a href="javascript:togglevis('fanyix16')" id="showbib">[Show BibTex]</a><br>
  </p></td>
</tr></tbody></table>
      <table class="bibtex" style="display:none;margin-top:20px;" id="fanyix16"><tbody><tr><td>
          <pre>@inproceedings{xiao-cvpr2016,
  title = {Track and Segment: An Iterative Unsupervised Approach for Video Object Proposals},
  author = {Xiao, Fanyi and Lee, Yong Jae},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  year = {2016}
}
          </pre>
       <!--</div>-->
       </td></tr></tbody></table>
<p></p>

<!--<h3 style="clear:both">Video</h3><br/><br/>
  <iframe width="800" height="450" src="http://www.youtube.com/embed/s5-30NKSwo8?version=3&fs=1&feature=player_embedded&fs=1&hd=1&ap=%2526fmt%3D22" frameborder="1" allowfullscreen></iframe>
</p>-->


<h3>Additional Materials</h3>
<p style="padding-left: 10px;	padding-right: 10px;">

<ul>
<li><a href="./files/videoseg_supp.zip"><b>Supplementary materials</b></a> to the main paper</li>
<li><a href="./files/segmentation.avi"><b>Results video</b></a></li>
</ul>


</p>

<h3>Source Code</h3>
<p style="padding-left: 10px;	padding-right: 10px;">
Please download VS_release.tar.gz and read the README inside. <br>
<a href="https://drive.google.com/file/d/0B0mwzANois91S0hBbmhEWXFmbnc/view?usp=sharing"><b>VS_release.tar.gz</b></a> (BETA)<br>
<a href="https://drive.google.com/file/d/0B0mwzANois91ejJCa3EwaGx5ZU0/view?usp=sharing"><b>SegTrackv2.tar.gz</b></a><br>
<a href="https://drive.google.com/file/d/0B0mwzANois91Qkhpa3YzVTNSNFk/view?usp=sharing"><b>VSNet.tar.gz</b></a>
</p>




<h3 style="clear:both">Acknowledgments</h3>
<p style="padding-left: 10px; padding-right: 10px;">
This research was supported partially by:
</p><ul>
<li>NVidia hardware grant</li>
<li>Amazon Web Services grant</li>
</ul>
<p></p>
<p style="padding-left: 10px; padding-right: 10px;">
Comments, questions to <a href="mailto:fanyix@cs.ucdavis.edu" target="_blank">Fanyi Xiao</a></p>
</div>





</body></html>